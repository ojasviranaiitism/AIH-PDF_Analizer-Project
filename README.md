# ğŸ“„ Persona-Driven Document Intelligence Engine

An **offline-first document analysis engine** designed to tackle information overload. It acts as an intelligent research assistant by analyzing a collection of PDF documents, understanding a user's specific **Persona** and **Job-to-be-Done**, and surfacing the most relevant sections and paragraphs.

> âœ… Entirely self-contained, CPU-optimized, and packaged in Docker for offline performanceâ€”perfect for hackathon constraints.

---

## âœ¨ Core Features

- **ğŸ§  Intelligent Ranking**: Uses a state-of-the-art Sentence-Transformer model to semantically rank document content by relevance to the userâ€™s intent.
- **ğŸ“‘ Structured Extraction**: Parses PDFs to identify headings and paragraphs by analyzing layout, font styles, and sizesâ€”going far beyond simple text dumps.
- **ğŸ›¡ï¸ Offline-First & Secure**: Fully functional without internet access. All models and dependencies are pre-packaged inside the Docker image.
- **âš¡ Lightweight & Efficient**: Runs smoothly on standard CPU hardware with a low memory footprint.

---

## ğŸš€ Why This Approach Excels

### ğŸ–¹ High-Performance PDF Parsing â€” *PyMuPDF*
We chose **PyMuPDF** for its ability to extract structured data with speed and precision. By analyzing font styles and sizes, we can distinguish section titles from paragraphsâ€”something basic text extraction libraries can't do.

### ğŸ” Efficient Semantic Search â€” *all-MiniLM-L6-v2*
This ~86MB Sentence-Transformer model offers a perfect trade-off between **accuracy, size, and speed**. It enables the system to **understand context and meaning**, not just keywordsâ€”while being lightweight enough for CPU-only environments.

### ğŸ“¦ Guaranteed Portability â€” *Docker*
The entire application is containerized. Using `--network none`, we prove that the app works completely offline, adhering to strict data/privacy and hackathon guidelines. This also ensures consistent results across different environments.

---

## âš™ï¸ Setup & Usage

### ğŸ”§ Prerequisites

- Git
- Docker Desktop

---

### ğŸ“ 1. Local Setup

Clone the repository and create the required folder structure:

```bash
# Clone the repository
git clone <your-repo-url>
cd persona-driven-document-intelligence-engine
```

Prepare the input directory:

```
persona-driven-document-intelligence-engine/
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ input.json
â”‚   â””â”€â”€ PDFs/
â”‚       â”œâ”€â”€ doc1.pdf
â”‚       â””â”€â”€ doc2.pdf
â””â”€â”€ ... (other project files)
```

Also, create an empty `output/` folder at the root for storing the results.

---

### ğŸ—ï¸ 2. Build Docker Image

From the root directory, build the Docker image:

```bash
docker build -t doc-intel-engine .
```

---

### â–¶ï¸ 3. Run the Engine

#### For macOS / Linux:

```bash
docker run --rm -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output --network none doc-intel-engine
```

#### For Windows (PowerShell):

```bash
docker run --rm -v ${pwd}/input:/app/input -v ${pwd}/output:/app/output --network none doc-intel-engine
```

After execution, the results will be saved as `output/output.json`.

---

## ğŸ› ï¸ Tech Stack

- **Backend**: Python  
- **AI/ML**: PyTorch, Sentence-Transformers (`all-MiniLM-L6-v2`)  
- **PDF Parsing**: PyMuPDF  
- **Containerization**: Docker  

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ approach_explanation.md
â”œâ”€â”€ models/
â”‚   â””â”€â”€ all-MiniLM-L6-v2/
â”œâ”€â”€ requirements.txt
â””â”€â”€ src/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ pdf_processor.py
    â””â”€â”€ relevance_engine.py
```
